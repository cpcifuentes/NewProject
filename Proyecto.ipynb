{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cpcifuentes/NewProject/blob/master/Proyecto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalación librerías"
      ],
      "metadata": {
        "id": "FXqUbjzLCShS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "Y6ZzAvfI0Fpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!wget https://www.dropbox.com/s/54jfodpv1h4d0kl/pyxvis.zip\n",
        "!unzip pyxvis.zip\n",
        "!rm pyxvis.zip\n",
        "print('PyXvis library downloaded.')\n",
        "!pip install scipy==1.2\n",
        "!pip3 install pybalu==0.2.5\n",
        "!pip install ./pyxvis\n",
        "# clear_output()\n",
        "print('Librerías instaladas.')"
      ],
      "metadata": {
        "id": "qIrdYptxCPkq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "894b1c70-a220-4e6c-f386-64ab10f867c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-04 00:41:19--  https://www.dropbox.com/s/54jfodpv1h4d0kl/pyxvis.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.85.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.85.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/54jfodpv1h4d0kl/pyxvis.zip [following]\n",
            "--2022-07-04 00:41:20--  https://www.dropbox.com/s/raw/54jfodpv1h4d0kl/pyxvis.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc711006feeeedc15dde7cd53a00.dl.dropboxusercontent.com/cd/0/inline/BoZ1-Kp_K0g8zGbqUMFOczoGARxmDT3lMyDNpl7kd28pP086LleXMnm3gcIlEezZl9XLpIbcnE6_m2Po4LoU9Wu--UUcpj3PM7CZXm5EpFAaFbmg-dbWIL4k1LQEYuohVszdxYRIrWOqaGZbmx20PCRQA2kqswHodh5XRrVFk2CuPw/file# [following]\n",
            "--2022-07-04 00:41:20--  https://uc711006feeeedc15dde7cd53a00.dl.dropboxusercontent.com/cd/0/inline/BoZ1-Kp_K0g8zGbqUMFOczoGARxmDT3lMyDNpl7kd28pP086LleXMnm3gcIlEezZl9XLpIbcnE6_m2Po4LoU9Wu--UUcpj3PM7CZXm5EpFAaFbmg-dbWIL4k1LQEYuohVszdxYRIrWOqaGZbmx20PCRQA2kqswHodh5XRrVFk2CuPw/file\n",
            "Resolving uc711006feeeedc15dde7cd53a00.dl.dropboxusercontent.com (uc711006feeeedc15dde7cd53a00.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc711006feeeedc15dde7cd53a00.dl.dropboxusercontent.com (uc711006feeeedc15dde7cd53a00.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BoZklLMOwYOTdTE1vh5vo4BLJZhIlYoLqgC2IQd9IS4hGrpvCqPssAGNyQLS7yhIjEPm6S_fqrkoYvp-HZjAOg0YhVpJbzb34zWiKpInKkaFCAAkRAQlPa5-ahXlORd52gPlXGUhBQ5QkeE5gVruijC9GRKN963s-kA7ecXLpQdHLK-jrHDujo57WQmbf-X9ohml4kyzowhfTmPSWs7txz__QJwWFF0eTWaYja2kh_uGK-O4B59MNza0xoJHUHncqEJN_poPlCNHLhzoMOUYHcdlUE8KQPsEAy8WVVB0rGCe-ZlugFk1qf3RpecZfLfU6QpQYDhlBF2bzKJ9aOxxHDiID2LjCG_s0QEDWICavHZFlvvHckrYMVUbNS40t0DQ8qHemKKlIfRTM0i4nDrmGUOCqA0sTk-VWJ71nXlJNiiyTw/file [following]\n",
            "--2022-07-04 00:41:21--  https://uc711006feeeedc15dde7cd53a00.dl.dropboxusercontent.com/cd/0/inline2/BoZklLMOwYOTdTE1vh5vo4BLJZhIlYoLqgC2IQd9IS4hGrpvCqPssAGNyQLS7yhIjEPm6S_fqrkoYvp-HZjAOg0YhVpJbzb34zWiKpInKkaFCAAkRAQlPa5-ahXlORd52gPlXGUhBQ5QkeE5gVruijC9GRKN963s-kA7ecXLpQdHLK-jrHDujo57WQmbf-X9ohml4kyzowhfTmPSWs7txz__QJwWFF0eTWaYja2kh_uGK-O4B59MNza0xoJHUHncqEJN_poPlCNHLhzoMOUYHcdlUE8KQPsEAy8WVVB0rGCe-ZlugFk1qf3RpecZfLfU6QpQYDhlBF2bzKJ9aOxxHDiID2LjCG_s0QEDWICavHZFlvvHckrYMVUbNS40t0DQ8qHemKKlIfRTM0i4nDrmGUOCqA0sTk-VWJ71nXlJNiiyTw/file\n",
            "Reusing existing connection to uc711006feeeedc15dde7cd53a00.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90876 (89K) [application/zip]\n",
            "Saving to: ‘pyxvis.zip’\n",
            "\n",
            "pyxvis.zip          100%[===================>]  88.75K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2022-07-04 00:41:21 (999 KB/s) - ‘pyxvis.zip’ saved [90876/90876]\n",
            "\n",
            "Archive:  pyxvis.zip\n",
            "   creating: pyxvis/\n",
            "  inflating: __MACOSX/._pyxvis       \n",
            "  inflating: pyxvis/.DS_Store        \n",
            "  inflating: __MACOSX/pyxvis/._.DS_Store  \n",
            "  inflating: pyxvis/LICENSE          \n",
            "  inflating: __MACOSX/pyxvis/._LICENSE  \n",
            "  inflating: pyxvis/README.md        \n",
            "  inflating: __MACOSX/pyxvis/._README.md  \n",
            "   creating: pyxvis/pyxvis/\n",
            "  inflating: __MACOSX/pyxvis/._pyxvis  \n",
            "  inflating: pyxvis/setup.py         \n",
            "  inflating: __MACOSX/pyxvis/._setup.py  \n",
            "  inflating: pyxvis/pyxvis/.DS_Store  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/._.DS_Store  \n",
            "   creating: pyxvis/pyxvis/processing/\n",
            "  inflating: __MACOSX/pyxvis/pyxvis/._processing  \n",
            "   creating: pyxvis/pyxvis/learning/\n",
            "  inflating: __MACOSX/pyxvis/pyxvis/._learning  \n",
            "   creating: pyxvis/pyxvis/io/\n",
            "  inflating: __MACOSX/pyxvis/pyxvis/._io  \n",
            "   creating: pyxvis/pyxvis/features/\n",
            "  inflating: __MACOSX/pyxvis/pyxvis/._features  \n",
            "   creating: pyxvis/pyxvis/simulation/\n",
            "  inflating: __MACOSX/pyxvis/pyxvis/._simulation  \n",
            "  inflating: pyxvis/pyxvis/__init__.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/.___init__.py  \n",
            "   creating: pyxvis/pyxvis/__pycache__/\n",
            "  inflating: __MACOSX/pyxvis/pyxvis/.___pycache__  \n",
            "   creating: pyxvis/pyxvis/geometry/\n",
            "  inflating: __MACOSX/pyxvis/pyxvis/._geometry  \n",
            "  inflating: pyxvis/pyxvis/processing/.DS_Store  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/processing/._.DS_Store  \n",
            "  inflating: pyxvis/pyxvis/processing/__init__.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/processing/.___init__.py  \n",
            "  inflating: pyxvis/pyxvis/processing/images.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/processing/._images.py  \n",
            "   creating: pyxvis/pyxvis/processing/helpers/\n",
            "  inflating: __MACOSX/pyxvis/pyxvis/processing/._helpers  \n",
            "  inflating: pyxvis/pyxvis/processing/segmentation.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/processing/._segmentation.py  \n",
            "  inflating: pyxvis/pyxvis/learning/gan.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/learning/._gan.py  \n",
            "  inflating: pyxvis/pyxvis/learning/pretrained.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/learning/._pretrained.py  \n",
            "  inflating: pyxvis/pyxvis/learning/evaluation.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/learning/._evaluation.py  \n",
            "  inflating: pyxvis/pyxvis/learning/__init__.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/learning/.___init__.py  \n",
            "  inflating: pyxvis/pyxvis/learning/cnn.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/learning/._cnn.py  \n",
            "  inflating: pyxvis/pyxvis/learning/transfer.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/learning/._transfer.py  \n",
            "  inflating: pyxvis/pyxvis/learning/classifiers.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/learning/._classifiers.py  \n",
            "  inflating: pyxvis/pyxvis/io/misc.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/io/._misc.py  \n",
            "  inflating: pyxvis/pyxvis/io/.DS_Store  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/io/._.DS_Store  \n",
            "  inflating: pyxvis/pyxvis/io/__init__.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/io/.___init__.py  \n",
            "  inflating: pyxvis/pyxvis/io/visualization.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/io/._visualization.py  \n",
            "  inflating: pyxvis/pyxvis/io/plots.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/io/._plots.py  \n",
            "  inflating: pyxvis/pyxvis/io/data.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/io/._data.py  \n",
            "  inflating: pyxvis/pyxvis/io/gdxraydb.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/io/._gdxraydb.py  \n",
            "  inflating: pyxvis/pyxvis/features/.DS_Store  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/features/._.DS_Store  \n",
            "  inflating: pyxvis/pyxvis/features/__init__.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/features/.___init__.py  \n",
            "  inflating: pyxvis/pyxvis/features/descriptors.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/features/._descriptors.py  \n",
            "  inflating: pyxvis/pyxvis/features/extraction.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/features/._extraction.py  \n",
            "  inflating: pyxvis/pyxvis/features/selection.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/features/._selection.py  \n",
            "  inflating: pyxvis/pyxvis/simulation/__init__.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/simulation/.___init__.py  \n",
            "  inflating: pyxvis/pyxvis/simulation/xsim.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/simulation/._xsim.py  \n",
            "  inflating: pyxvis/pyxvis/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/__pycache__/.___init__.cpython-36.pyc  \n",
            "  inflating: pyxvis/pyxvis/geometry/projective.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/geometry/._projective.py  \n",
            "  inflating: pyxvis/pyxvis/geometry/__init__.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/geometry/.___init__.py  \n",
            "  inflating: pyxvis/pyxvis/geometry/epipolar.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/geometry/._epipolar.py  \n",
            "  inflating: pyxvis/pyxvis/processing/helpers/kfunctions.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/processing/helpers/._kfunctions.py  \n",
            "  inflating: pyxvis/pyxvis/processing/helpers/__init__.py  \n",
            "  inflating: __MACOSX/pyxvis/pyxvis/processing/helpers/.___init__.py  \n",
            "PyXvis library downloaded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scipy==1.2\n",
            "  Downloading scipy-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (26.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.2) (1.21.6)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.3.8 requires scipy>=1.2.1, but you have scipy 1.2.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pybalu==0.2.5\n",
            "  Downloading pybalu-0.2.5-cp37-cp37m-manylinux1_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.7/dist-packages (from pybalu==0.2.5) (4.64.0)\n",
            "Collecting imageio>=2.5.0\n",
            "  Downloading imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 44.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.7/dist-packages (from pybalu==0.2.5) (1.21.6)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from pybalu==0.2.5) (0.18.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from pybalu==0.2.5) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from pybalu==0.2.5) (1.2.0)\n",
            "Collecting pillow>=8.3.2\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 47.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->pybalu==0.2.5) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->pybalu==0.2.5) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->pybalu==0.2.5) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->pybalu==0.2.5) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2->pybalu==0.2.5) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2->pybalu==0.2.5) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2->pybalu==0.2.5) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2->pybalu==0.2.5) (1.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2->pybalu==0.2.5) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2->pybalu==0.2.5) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.2->pybalu==0.2.5) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.2->pybalu==0.2.5) (1.1.0)\n",
            "Installing collected packages: pillow, imageio, pybalu\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed imageio-2.19.3 pillow-9.2.0 pybalu-0.2.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./pyxvis\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.7/dist-packages (from pyxvis==0.0.1) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyxvis==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from pyxvis==0.0.1) (0.18.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from pyxvis==0.0.1) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyxvis==0.0.1) (1.0.2)\n",
            "Requirement already satisfied: pybalu in /usr/local/lib/python3.7/dist-packages (from pyxvis==0.0.1) (0.2.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pyxvis==0.0.1) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyxvis==0.0.1) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyxvis==0.0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyxvis==0.0.1) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyxvis==0.0.1) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->pyxvis==0.0.1) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->pyxvis==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.7/dist-packages (from pybalu->pyxvis==0.0.1) (4.64.0)\n",
            "Requirement already satisfied: imageio>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from pybalu->pyxvis==0.0.1) (2.19.3)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.7/dist-packages (from imageio>=2.5.0->pybalu->pyxvis==0.0.1) (9.2.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->pyxvis==0.0.1) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->pyxvis==0.0.1) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->pyxvis==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyxvis==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyxvis==0.0.1) (1.1.0)\n",
            "Building wheels for collected packages: pyxvis\n",
            "  Building wheel for pyxvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyxvis: filename=pyxvis-0.0.1-py3-none-any.whl size=67637 sha256=f193d8f8042d89668c3944c6fb0a09676c05c11ea2ceea03778dcf5f2a0ceba9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9s836eph/wheels/11/0e/e5/4e9331d67995eb55985def2c52ac94b3af5a21f262793a9b45\n",
            "Successfully built pyxvis\n",
            "Installing collected packages: pyxvis\n",
            "Successfully installed pyxvis-0.0.1\n",
            "Librerías instaladas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from   pyxvis.features.extraction import extract_features\n",
        "from   sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "from   sklearn.decomposition import FastICA\n",
        "from   sklearn.cross_decomposition import PLSRegression\n",
        "from   sklearn.neighbors import KNeighborsClassifier\n",
        "from   sklearn.feature_selection import RFECV, RFE, SelectKBest, chi2, SelectFromModel \n",
        "from   sklearn.ensemble import RandomForestClassifier\n",
        "from   sklearn.linear_model import LogisticRegression\n",
        "from   sklearn.naive_bayes import GaussianNB\n",
        "from   sklearn.neural_network import MLPClassifier\n",
        "from   sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
        "from   sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from   lightgbm import LGBMClassifier\n",
        "import joblib\n",
        "import sys\n",
        "sys.modules['sklearn.externals.joblib'] = joblib\n",
        "from   mlxtend.feature_selection import SequentialFeatureSelector as mlxsfs\n",
        "from   pybalu.feature_transformation import normalize, pca\n",
        "from   pybalu.feature_selection import clean, sfs, exsearch\n",
        "from   pybalu.feature_extraction import lbp_features, haralick_features, gabor_features, hog_features, basic_int_features\n",
        "from   tqdm.auto import tqdm\n",
        "clear_output()\n",
        "print('Librerías cargadas.')"
      ],
      "metadata": {
        "id": "2C4s3fQHCRdz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "2c3b57fd-1690-4fd9-b36a-b552297a4b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-0654e899e23f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m   \u001b[0mpybalu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlbp_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mharalick_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgabor_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhog_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasic_int_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m   \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Librerías cargadas.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clear_output' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sección nueva"
      ],
      "metadata": {
        "id": "pxh8WQmHQceo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Getter\n",
        "Given a name, it will download a thing"
      ],
      "metadata": {
        "id": "QU7YLuY84Cjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "links = {\n",
        "    \"Bicicletas\" :\"https://www.dropbox.com/s/nznuspgkuk9pax3/Bicicletas.zip\",\n",
        "    \"Cachipun\" :\"https://www.dropbox.com/s/cwr55d7mik3b9gt/Cachipun.zip\",\n",
        "    \"Espinas\" :\"https://www.dropbox.com/s/xb3qhvukiquqk3k/Espinas.zip\",\n",
        "    \"Letras\" :\"https://www.dropbox.com/s/uhpnih2ov6kn3l6/Letras.zip\",\n",
        "    \"Lunares\" :\"https://www.dropbox.com/s/atml3zlyvt0b83z/Lunares.zip\",\n",
        "}\n",
        "\n",
        "def get_db(name:str, links=links) -> None:\n",
        "  '''\n",
        "    Recibe un nombre y un diccionario de links, busca en el diccionario la direccion en la que esta\n",
        "    la bases de datos, descarga el archivo zip, lo descomprime con unzip y elimina el comprimido\n",
        "\n",
        "      name[str]: El nombre del archivo\n",
        "      links[dict](Opcional): Diccionario con links\n",
        "  '''\n",
        "  link = links[name]\n",
        "  os.system(f\"wget {link}\")\n",
        "  os.system(f\"unzip {name}.zip\")\n",
        "  os.system(f\"rm -rf {name}.zip\")"
      ],
      "metadata": {
        "id": "06E-HNA-6o4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_db('Lunares')"
      ],
      "metadata": {
        "id": "gBR7BeOoGVsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Geometric feature Extractors\n",
        "def get_binaryFeature(image:np.ndarray, feature:str) -> np.array:\n",
        "  mean = np.mean(image)\n",
        "  R = (image > mean)*1\n",
        "  return extract_features(feature, bw=image)\n",
        "\n",
        "def get_hu(image:np.ndarray) -> np.array:\n",
        "  return cv.HuMoments(cv.moments(image)).flatten()\n",
        "\n",
        "def get_flusser(image: np.ndarray) -> np.array:\n",
        "  return get_binaryFeature(image, 'flusser')\n",
        "\n",
        "def get_contrast(image: np.ndarray) -> np.array:\n",
        "  return get_binaryFeature(image, 'contrast')\n",
        "\n",
        "def get_fourierDes(image: np.ndarray) -> np.array:\n",
        "  return get_binaryFeature(image, 'fourierdes')\n",
        "\n",
        "def get_gupta(image: np.ndarray) -> np.array:\n",
        "  return get_binaryFeature(image, 'gupta')\n",
        "\n",
        "def get_basicGeo(image:np.ndarray) -> np.array:\n",
        "  return get_binaryFeature(image, 'basicgeo')\n",
        "\n",
        "def get_ellipse(image:np.ndarray) -> np.array:\n",
        "  return get_binaryFeature(image, 'ellipse')\n",
        "\n",
        "def get_centroid(image:np.ndarray) -> np.array:\n",
        "  return get_binaryFeature(image, 'centroid')\n",
        "\n",
        "def get_symmetry(image):\n",
        "  radial=0\n",
        "  h = 0\n",
        "  v = 0\n",
        "  for i in range(int(image.shape[1])):\n",
        "    for j in range(int(image.shape[0])):\n",
        "      i_alt = image.shape[1] - i - 1\n",
        "      h += image[j,i] == image[j,i_alt]\n",
        "      \n",
        "  for i in range(int(image.shape[1])):\n",
        "    for j in range(int(image.shape[0])):\n",
        "      j_alt = image.shape[0] - j - 1\n",
        "      v += image[j,i] == image[j_alt,i]\n",
        "\n",
        "  for i in range(int(image.shape[1])):\n",
        "    for j in range(int(image.shape[0])):\n",
        "      i_alt = image.shape[1] - i - 1\n",
        "      j_alt = image.shape[0] - j - 1\n",
        "      radial += image[j,i] == image[j_alt,i_alt]\n",
        "\n",
        "  h /= image.shape[0]*image.shape[1]\n",
        "  v /= image.shape[0]*image.shape[1]\n",
        "  radial /= image.shape[0]*image.shape[1]\n",
        "  return np.array([v, h, radial])\n",
        "\n",
        "def get_area(image:np.ndarray) -> np.array:\n",
        "  mean = np.mean(image)\n",
        "  return np.array([np.sum(image>mean)/(image.shape[0]*image.shape[1])])\n",
        "\n",
        "## Texture feature extractors\n",
        "def get_lbp(image:np.ndarray,hdiv,vdiv,mapping) -> np.array:\n",
        "  return lbp_features(image, hdiv=hdiv, vdiv=vdiv, mapping=mapping)\n",
        "\n",
        "def get_haralick(image:np.ndarray,dis) -> np.array:\n",
        "  return haralick_features(image, distance=dis)\n",
        "\n",
        "def get_gabor(image:np.ndarray,rot,dil) -> np.array:\n",
        "  return gabor_features(image, rotations=rot, dilations=dil)\n",
        "\n",
        "def get_hog(image:np.ndarray,hdiv,vdiv,bins) -> np.array:\n",
        "  return hog_features(image, v_windows=vdiv, h_windows=hdiv, n_bins=bins)\n",
        "\n",
        "def get_basicint(image:np.ndarray) -> np.array:\n",
        "  return basic_int_features(image)\n",
        "\n",
        "def get_gabor(image:np.ndarray, rot, dil) -> np.array:\n",
        "  return gabor_features(image, rotations=rot, dilations=dil)\n",
        "\n",
        "# Funciones encargadas de la obtención de imagenes\n",
        "def open_image(path, channels='single') -> np.ndarray:\n",
        "  if channels == 'single':\n",
        "    return cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
        "  return cv.imread(path)\n",
        "\n",
        "def get_image(kind, idx, channel) -> np.ndarray:\n",
        "  ch = ['peaton', 'fondo', 'bicicleta'][kind-1]\n",
        "  path = f'./Bicicletas/{kind:02}_{ch}/person_{kind:02}_{idx:04}.png'\n",
        "  return open_image(path, channel)"
      ],
      "metadata": {
        "id": "7EgpBmb8jUY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "class AutoPR:\n",
        "  # Utilizando parametros en formato json\n",
        "  def __init__(self, param_route: str) -> None:\n",
        "    try:\n",
        "      with open(param_route, 'r') as f:\n",
        "        params = json.load(f)['Parameters']\n",
        "        print(f\"Loading Parameters from {param_route}\")\n",
        "    except Exception as error:\n",
        "      print(f'While reading the parameters file, an exception ocurred:\\n {error}')\n",
        "    else:\n",
        "      self.dataset = params.get('Dataset')\n",
        "      print(\"\\t- Dataset:\",self.dataset)\n",
        "      # Verificar si es None\n",
        "      self.geo_features = params.get('GeoFeatures') \n",
        "      print(\"\\t- Geometric Features:\",self.geo_features)\n",
        "      # Verificar si es None\n",
        "      self.tex_features = params.get('TexFeatures')\n",
        "      print(\"\\t- Texture Features:\",self.tex_features)\n",
        "      # Verificar si es None\n",
        "      self.feat_comb = params.get('FeatureCombination')\n",
        "      print(\"\\t- Feature Combination:\",self.feat_comb)\n",
        "      self.classifiers = params.get('Classifiers')\n",
        "      print(\"\\t- Classifiers:\",self.classifiers)\n",
        "      self.evaluation = params.get('Evaluation')\n",
        "      print(\"\\t- Evaluation:\",self.evaluation)\n",
        "      self.evaluation = self.evaluation[0][1][0]\n",
        "      self.trained_cls = {}\n",
        "\n",
        "      self.feature_extractor_functions = {\n",
        "        'bas': get_basicint,\n",
        "        'har': get_haralick,\n",
        "        'hog': get_hog,\n",
        "        'lbp': get_lbp,\n",
        "        'con': get_contrast,\n",
        "        'fou': get_fourierDes,\n",
        "        'are': get_area,\n",
        "        'cen': get_centroid,\n",
        "        'ell': get_ellipse,\n",
        "        'flu': get_flusser,\n",
        "        'geo': get_basicGeo,\n",
        "        'gup': get_gupta,\n",
        "        'hu': get_hu,\n",
        "        'sym': get_symmetry\n",
        "      }\n",
        "\n",
        "      # El propósito de esta variable es almacenar a las imagenes para cada llamada de feature no encontrada\n",
        "      self.db = None\n",
        "\n",
        "  def load_db(self,path):\n",
        "    \n",
        "  def extract_features(self, feature:list) -> np.array:\n",
        "    # TODO\n",
        "    args = feature[1]\n",
        "    name = feature[0].lower()\n",
        "\n",
        "    # Aqui hay que definir la base de datos a entregarle a las funciones, si no está hay que obtenerla\n",
        "    # Leer imagen y almacenarla en self.db\n",
        "    X = None\n",
        "\n",
        "    # Obtenemos la funcion a ejecutar\n",
        "    func = self.feature_extractor_functions[name]\n",
        "  \n",
        "    # Se retorna una matriz de caracteristicas resultado de la aplicacion de la funcion\n",
        "    return func(X, *args)\n",
        "\n",
        "  def load_features(self) -> np.ndarray:\n",
        "    '''\n",
        "    Carga las características especificadas por los atributos (geo_features,tex_features), desde las siguientes\n",
        "    carpetas: features/Geo/Base_de_Datos/ y/o features/Tex/Base_de_Datos/.\n",
        "    '''\n",
        "    # TODO: calculate features if not saved\n",
        "    features = []\n",
        "\n",
        "    if self.geo_features:\n",
        "      geo_features = []\n",
        "      for feature in self.geo_features:\n",
        "        path = f'./drive/Shareddrives/Patrones/features/{self.dataset}/X_{feature[0][:3].lower()}.npy'\n",
        "        if os.path.isfile(path):\n",
        "          geo_features.append(np.load(path))\n",
        "        else: \n",
        "          # TODO\n",
        "          X = self.extract_features(feature)\n",
        "          np.save(X, path)\n",
        "          geo_features.append(X)\n",
        "      if geo_features:\n",
        "        features.extend(geo_features)\n",
        "\n",
        "    if self.tex_features:\n",
        "      tex_features = []\n",
        "      for feature in self.tex_features:\n",
        "        # Se extraen el nombre y los argumentos y se arma el string\n",
        "        name = feature[0][:3].lower()\n",
        "        args = list(map(lambda x: str(x), feature[1]))\n",
        "        path = f'./drive/Shareddrives/Patrones/features/{self.dataset}/X_{name}_{\"_\".join(args)}.npy'\n",
        "        if os.path.isfile(path):\n",
        "          tex_features.append(np.load(path))\n",
        "        else: \n",
        "          # TODO\n",
        "          X = self.extract_features(feature)\n",
        "          np.save(X, path)\n",
        "          tex_features.append(X)\n",
        "      if tex_features:\n",
        "        features.extend(tex_features)\n",
        "\n",
        "    X = np.concatenate(features,axis=1)\n",
        "    y = np.load(f'./drive/Shareddrives/Patrones/features/{self.dataset}/Y_{self.dataset}.npy')\n",
        "    return X, y\n",
        "\n",
        "  def feat_select_trans(self, X, y):\n",
        "    '''\n",
        "    Aplica las strategies de seleccion y transformacion indicadas\n",
        "    '''\n",
        "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.30, random_state=42,stratify=y)\n",
        "    # clean\n",
        "    sclean = clean(Xtrain)\n",
        "\n",
        "    Xtrain_clean = Xtrain[:, sclean]\n",
        "    Xtest_clean = Xtest[:, sclean]\n",
        "\n",
        "    # normalizacion min max\n",
        "    ma = Xtrain_clean.max(0)\n",
        "    mi = Xtrain_clean.min(0)\n",
        "    md = ma-mi\n",
        "    a = 1/md\n",
        "    b = -mi/md\n",
        "\n",
        "    Xtrain_norm = Xtrain_clean * a + b\n",
        "    Xtest_norm = Xtest_clean * a + b\n",
        "\n",
        "    strategies = []\n",
        "    print(\"Feature Combination\")\n",
        "    if self.feat_comb:\n",
        "      # selection_transformation = lista de cada seleccion o transformacion a realizar\n",
        "      for selection_transformation in self.feat_comb:\n",
        "        print(\"\\t- Combination\",selection_transformation)\n",
        "        \n",
        "        Xtrain_copy = Xtrain_norm.copy()\n",
        "        Xtest_copy = Xtest_norm.copy()\n",
        "        name = \"\"\n",
        "\n",
        "        # strat = nombre de la seleccion/transformacion y sus parametros\n",
        "        for strat in selection_transformation:\n",
        "          print(\"\\t- Strategy\",strat)\n",
        "          if isinstance(strat[1],list):\n",
        "            name = name + strat[0] + \"_\" + str(strat[1][0])\n",
        "            print(\"\\t\\t- Params\",strat[1][0])\n",
        "          else:\n",
        "            name = name + strat[0]\n",
        "          if strat[0] == \"SFS\":\n",
        "            p = strat[1][0]\n",
        "            Xtrain_copy, Xtest_copy = self.sfs(Xtrain_copy, Xtest_copy, ytrain, p)\n",
        "          \n",
        "          elif strat[0] == \"exsearch\":\n",
        "            p = strat[1][0]\n",
        "            Xtrain_copy, Xtest_copy = self.exsearch(Xtrain_copy, Xtest_copy, ytrain, p)\n",
        "\n",
        "          elif strat[0] == \"RFECV\":\n",
        "            Xtrain_copy, Xtest_copy = self.rfecv(Xtrain_copy, Xtest_copy, ytrain)\n",
        "\n",
        "          elif strat[0] == \"RFE\":\n",
        "            Xtrain_copy, Xtest_copy = self.rfecv(Xtrain_copy, Xtest_copy, ytrain)\n",
        "\n",
        "          elif strat[0] == \"SBS\":\n",
        "            p = strat[1][0]\n",
        "            Xtrain_copy, Xtest_copy = self.sbs(Xtrain_copy, Xtest_copy, ytrain, p)\n",
        "\n",
        "          elif strat[0] == \"selectkbest\":\n",
        "            Xtrain_copy, Xtest_copy = self.select_k_best(Xtrain_copy, Xtest_copy, ytrain)\n",
        "\n",
        "          elif strat[0] == \"PCA\":\n",
        "            p = strat[1][0]\n",
        "            Xtrain_copy, Xtest_copy = self.pca(Xtrain_copy, Xtest_copy, p)\n",
        "\n",
        "          elif strat[0] == \"ICA\":\n",
        "            p = strat[1][0]\n",
        "            Xtrain_copy, Xtest_copy = self.ica(Xtrain_copy, Xtest_copy, ytrain, n=p)\n",
        "\n",
        "          elif strat[0] == \"PLSR\":\n",
        "            p = strat[1][0]\n",
        "            Xtrain_copy, Xtest_copy = self.plsr(Xtrain_copy, Xtest_copy, n=p)\n",
        "\n",
        "        strategies.append((name,Xtrain_copy, Xtest_copy))\n",
        "        \n",
        "    return strategies, ytrain, ytest\n",
        "\n",
        "  # Funciones seleccion de caracteristicas\n",
        "  def sfs(self, Xtrain, Xtest, ytrain, p=10):\n",
        "    sel = sfs(Xtrain, ytrain, p)\n",
        "    Xtrain_sel = Xtrain[:,sel]\n",
        "    Xtest_sel  = Xtest[:,sel]\n",
        "    return Xtrain_sel, Xtest_sel\n",
        "\n",
        "  def exsearch(self, Xtrain, Xtest, ytrain, p=10):\n",
        "    sel = exsearch(Xtrain, ytrain, p)\n",
        "    Xtrain_sel = Xtrain[:,sel]\n",
        "    Xtest_sel  = Xtest[:,sel]\n",
        "    return Xtrain_sel, Xtest_sel\n",
        "\n",
        "  def rfecv(self, Xtrain, Xtest, ytrain, kern=\"linear\", stp=1, v=5):\n",
        "    estimator = SVC(kernel=kern)\n",
        "\n",
        "    selector  = RFECV(estimator, step=stp,cv=v)\n",
        "    selector  = selector.fit(Xtrain, ytrain)\n",
        "    sel       = np.nonzero(selector.support_)[0]\n",
        "\n",
        "    Xtrain_sel = Xtrain[:,sel]\n",
        "    Xtest_sel  = Xtest[:,sel]\n",
        "    return Xtrain_sel, Xtest_sel\n",
        "\n",
        "  def rfe(self, Xtrain, Xtest, ytrain, kern=\"linear\"):\n",
        "    estimator = SVC(kernel=kern)\n",
        "\n",
        "    selector  = RFE(estimator)\n",
        "    selector  = selector.fit(Xtrain, ytrain)\n",
        "    sel       = np.nonzero(selector.support_)[0]\n",
        "\n",
        "    Xtrain_sel = Xtrain[:,sel]\n",
        "    Xtest_sel  = Xtest[:,sel]\n",
        "    return Xtrain_sel, Xtest_sel\n",
        "\n",
        "  def sbs(self, Xtrain, Xtest, ytrain, estimator, p=10, v=10):\n",
        "    forward = False\n",
        "    sbs = mlxsfs(estimator, k_features=p,forward=forward,floating=False,scoring='accuracy',cv=v)\n",
        "\n",
        "    sbs = sbs.fit(Xtrain, ytrain)\n",
        "    sel = list(sbs.k_feature_idx_)\n",
        "\n",
        "    Xtrain_sbs = Xtrain[:,sel]\n",
        "    Xtest_sbs  = Xtest[:,sel]\n",
        "    return Xtrain_sbs, Xtest_sbs\n",
        "\n",
        "  def select_k_best(self, Xtrain, Xtest, ytrain, p=10):\n",
        "    model =  SelectKBest(chi2,k=p)\n",
        "\n",
        "    eps = 1e-8\n",
        "    model.fit(Xtrain+eps, ytrain)  \n",
        "\n",
        "    sel        = np.nonzero(model.get_support())[0]\n",
        "\n",
        "    Xtrain_sel = Xtrain[:,sel]\n",
        "    Xtest_sel  = Xtest[:,sel]\n",
        "    return Xtrain_sel, Xtest_sel\n",
        "\n",
        "  # transformacion de caracteristicas\n",
        "  def pca(self, Xtrain, Xtest, n=10):\n",
        "    Xtrain_pca, _, A, Xm, _ = pca(Xtrain, n_components=n)\n",
        "    Xtest_pca = np.matmul(Xtest - Xm, A)\n",
        "    return Xtrain_pca, Xtest_pca\n",
        "\n",
        "  def ica(self, Xtrain, Xtest, ytrain, n=10, rs=0):\n",
        "    ica = FastICA(n_components=n, random_state=rs)\n",
        "    ica.fit(Xtrain, ytrain)    \n",
        "    Xtrain_ica = ica.transform(Xtrain)\n",
        "    Xtest_ica  = ica.transform(Xtest)\n",
        "    return Xtrain_ica, Xtest_ica\n",
        "\n",
        "  def plsr(self, Xtrain, Xtest, ytrain, n=10):\n",
        "    plsr = PLSRegression(n_components=n)    \n",
        "    plsr.fit(Xtrain, ytrain)    \n",
        "    Xtrain_plsr = plsr.transform(Xtrain)\n",
        "    Xtest_plsr  = plsr.transform(Xtest)\n",
        "    return Xtrain_plsr, Xtest_plsr\n",
        "\n",
        "  def model_selection(self):\n",
        "    # Separar datos entre train y test\n",
        "    n_folds = self.evaluation\n",
        "    # proportion_crossval = .8\n",
        "    cv_value = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=1)\n",
        "\n",
        "    # Por cada selector/transformador de caracteristicas\n",
        "    accuracy = {}\n",
        "\n",
        "    # Load\n",
        "    X, y = self.load_features()\n",
        "\n",
        "    # feat_select_trans ya hace split entre train y test\n",
        "    strategies, y_train, y_test = self.feat_select_trans(X, y)\n",
        "\n",
        "    self.classification()\n",
        "\n",
        "    for i in range(len(strategies)):\n",
        "      # El selector de características, se asume que este no está calculado ya\n",
        "      # En caso de que ya lo esté, reemplazar por Xprime = self.selectors[i][<train>]\n",
        "      # Strategies contiene a las tuplas Xtrain y Xtest \n",
        "      strat_name, X_train, X_test = strategies[i]\n",
        "      for name in self.trained_cls.keys():\n",
        "        accuracy[i,name] = np.mean(cross_val_score(\n",
        "            self.trained_cls[name], \n",
        "            X_train, \n",
        "            y_train, \n",
        "            scoring='accuracy', \n",
        "            cv = cv_value\n",
        "        ))\n",
        "    # Mejor indice de la estrategia y llave de clasificador\n",
        "    iMax, nameMax = 0, \"\"\n",
        "    accMax = -1\n",
        "    for (strat_index,model_name),acc in accuracy.items():\n",
        "      if accMax < acc:\n",
        "        iMax, accMax, nameMax = strat_index, acc, model_name\n",
        "    best_strat_name, X_train_prime, X_test_prime = strategies[iMax] # Es tupla Xtrain, Xtest\n",
        "    acc = self.holdout(X_train_prime, y_train, X_test_prime, y_test, self.trained_cls[nameMax])\n",
        "    # Retorna nombre de la mejor estrategia y clasificador, con sus respectivos parametros, el modelo y su accuracy\n",
        "    return best_strat_name, nameMax, self.trained_cls[nameMax], acc\n",
        "\n",
        "  def holdout(self, X_train, y_train, X_test, y_test, cls):\n",
        "    '''\n",
        "    Recibe X_train y X_test junto con y_test y obtiene el accuracy.\n",
        "    ''' \n",
        "    cls.fit(X_train,y_train)\n",
        "    y_pred = cls.predict(X_test)\n",
        "    return sum([ 1 if y_pred[i] == y_test[i] else 0 for i in range(y_test.shape[0])])/y_test.shape[0]\n",
        "\n",
        "  # Entrenamiento del clasificador\n",
        "  def classification(self):\n",
        "\n",
        "    for classifier in self.classifiers:\n",
        "      name, hiperpar = classifier\n",
        "\n",
        "      if name == 'SVM':\n",
        "        model = SVC(kernel=hiperpar[0])\n",
        "      elif name == 'KNN':\n",
        "        model = KNeighborsClassifier(n_neighbors=hiperpar[0])\n",
        "      elif name == 'RandomForest':\n",
        "        model = RandomForestClassifier(max_depth=hiperpar[0], n_estimators=hiperpar[1])\n",
        "      elif name == 'NaiveBayes':\n",
        "        model = GaussianNB()\n",
        "      elif name == 'NN':\n",
        "        model = MLPClassifier(alpha=hiperpar[0], hidden_layer_sizes=hiperpar[1], \n",
        "                      random_state=1,max_iter=1000)\n",
        "      elif name == 'LogisticRegression':\n",
        "        model = LogisticRegression(C=hiperpar[0],solver=\"lbfgs\",max_iter=1000)\n",
        "      elif name == 'QDA':\n",
        "        model = QDA()\n",
        "\n",
        "      key = name + \"_\" + \"_\".join([str(par) for par in hiperpar])\n",
        "      self.trained_cls[key] = model\n"
      ],
      "metadata": {
        "id": "pHgpKwRk5VRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = './drive/Shareddrives/Patrones/parametros_finales.json'\n",
        "\n",
        "prueba = AutoPR(root)\n",
        "X, y = prueba.load_features()\n",
        "strat_name, class_name, mo, acc = prueba.model_selection()\n",
        "print(\"Results:\")\n",
        "print(\"\\t- Best Strategy:\",strat_name)\n",
        "print(\"\\t- Best Classifier:\",class_name)\n",
        "print(\"\\t- Accuracy:\",acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "5hT2JumUi6Vq",
        "outputId": "c49d11f0-a9df-427d-f675-0d44b4ae576d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Parameters from ./drive/Shareddrives/Patrones/parametros_finales.json\n",
            "\t- Dataset: Lunares\n",
            "\t- Geometric Features: None\n",
            "\t- Texture Features: [['LBP', [3, 3, 'r']], ['LBP', [3, 3, 'g']], ['LBP', [3, 3, 'b']], ['Haralick', [2]], ['Haralick', [3]]]\n",
            "\t- Feature Combination: [[['SFS', [50]], ['PCA', [10]]], [['SFS', [10]], ['ICA', [5]]]]\n",
            "\t- Classifiers: [['SVM', ['linear']], ['SVM', ['rbf']], ['NN', [1e-05, [12, 12]]], ['NN', [1e-05, [24, 24]]], ['KNN', [15]], ['QDA', []]]\n",
            "\t- Evaluation: [['CV', [10]]]\n",
            "./drive/Shareddrives/Patrones/features/Lunares/X_lbp_3_3_r.npy\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-ee6ec01116c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprueba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoPR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprueba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mstrat_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprueba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-6e337b1c7c97>\u001b[0m in \u001b[0;36mload_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m           \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m           \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m           \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m           \u001b[0mtex_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-6e337b1c7c97>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, feature)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Se retorna una matriz de caracteristicas resultado de la aplicacion de la funcion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mload_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-8075a07d95de>\u001b[0m in \u001b[0;36mget_lbp\u001b[0;34m(image, hdiv, vdiv, mapping)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m## Texture feature extractors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_lbp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhdiv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvdiv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlbp_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdiv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvdiv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_haralick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pybalu/feature_extraction/lbp.py\u001b[0m in \u001b[0;36mlbp_features\u001b[0;34m(image, region, show, labels, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mnum_patterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m59\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unknown mapping: '{mapping}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mradius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'radius'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown mapping: 'r'"
          ]
        }
      ]
    }
  ]
}